{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andli28/HF-Deep-RL/blob/main/unit7_RL_SoccerTwos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upgrade to python 3.9"
      ],
      "metadata": {
        "id": "0cGhlj8zHk8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKgOhsQeNzyp",
        "outputId": "eac3a640-bc32-4102-af89-3ab526aaa495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:18\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create --name rl python=3.9\n",
        "!conda activate rl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5fKtO8MNpnE",
        "outputId": "b3503b21-c875-4a11-b55a-c999d7222787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 22.9.0\n",
            "  latest version: 22.11.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/rl\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2022.12.7  |       ha878542_0         143 KB  conda-forge\n",
            "    ld_impl_linux-64-2.40      |       h41732ed_0         688 KB  conda-forge\n",
            "    openssl-3.0.8              |       h0b41bf4_0         2.5 MB  conda-forge\n",
            "    pip-23.0                   |     pyhd8ed1ab_0         1.3 MB  conda-forge\n",
            "    python-3.9.16              |h2782a2a_0_cpython        23.0 MB  conda-forge\n",
            "    setuptools-67.3.1          |     pyhd8ed1ab_0         564 KB  conda-forge\n",
            "    tzdata-2022g               |       h191b570_0         106 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        28.3 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge None\n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu None\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4 None\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2022.12.7-ha878542_0 None\n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.40-h41732ed_0 None\n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 None\n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-12.2.0-h65d4601_19 None\n",
            "  libgomp            conda-forge/linux-64::libgomp-12.2.0-h65d4601_19 None\n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0 None\n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.40.0-h753d276_0 None\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000 None\n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4 None\n",
            "  ncurses            conda-forge/linux-64::ncurses-6.3-h27087fc_1 None\n",
            "  openssl            conda-forge/linux-64::openssl-3.0.8-h0b41bf4_0 None\n",
            "  pip                conda-forge/noarch::pip-23.0-pyhd8ed1ab_0 None\n",
            "  python             conda-forge/linux-64::python-3.9.16-h2782a2a_0_cpython None\n",
            "  readline           conda-forge/linux-64::readline-8.1.2-h0f457ee_0 None\n",
            "  setuptools         conda-forge/noarch::setuptools-67.3.1-pyhd8ed1ab_0 None\n",
            "  tk                 conda-forge/linux-64::tk-8.6.12-h27826a3_0 None\n",
            "  tzdata             conda-forge/noarch::tzdata-2022g-h191b570_0 None\n",
            "  wheel              conda-forge/noarch::wheel-0.38.4-pyhd8ed1ab_0 None\n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "python-3.9.16        | 23.0 MB   | : 100% 1.0/1 [00:01<00:00,  1.73s/it]               \n",
            "tzdata-2022g         | 106 KB    | : 100% 1.0/1 [00:00<00:00,  3.63it/s]\n",
            "setuptools-67.3.1    | 564 KB    | : 100% 1.0/1 [00:00<00:00,  4.09it/s]\n",
            "openssl-3.0.8        | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  4.04it/s]\n",
            "ld_impl_linux-64-2.4 | 688 KB    | : 100% 1.0/1 [00:00<00:00,  8.98it/s]\n",
            "pip-23.0             | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.54it/s]\n",
            "ca-certificates-2022 | 143 KB    | : 100% 1.0/1 [00:00<00:00, 11.68it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate rl\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Retrieving notices: ...working... done\n",
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Follow regular instructions"
      ],
      "metadata": {
        "id": "4jf9dSGpKCel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch"
      ],
      "metadata": {
        "id": "lFhlcFqO9WCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMuw71XZ9KVv"
      },
      "outputs": [],
      "source": [
        "!git clone --branch aivsai https://github.com/huggingface/ml-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/ml-agents/ml-agents-envs\n",
        "!pip install /content/ml-agents/ml-agents"
      ],
      "metadata": {
        "id": "YtlQDAKZDqy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load [SoccerTwos.zip](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view) from local machine."
      ],
      "metadata": {
        "id": "pla6qstvCu-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip SoccerTwos.zip -d SoccerTwos"
      ],
      "metadata": {
        "id": "k5i0Lm4RCQrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod -R 755 /content/SoccerTwos/SoccerTwos.x86_64"
      ],
      "metadata": {
        "id": "o9qeuf08QJg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# protobuf was throwing a version error, this fixes the error, and runs slower \n",
        "import os\n",
        "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION']='python'"
      ],
      "metadata": {
        "id": "PnrZ2sPOPqKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn /content/ml-agents/config/poca/SoccerTwos.yaml --env /content/SoccerTwos/SoccerTwos.x86_64 --run-id=\"resnet\" --no-graphics"
      ],
      "metadata": {
        "id": "OHffVc6nDEYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c87d441-4657-4ed2-d256-afdd063b9036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 0.31.0.dev0,\n",
            "  ml-agents-envs: 0.31.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 1.8.1+cu102\n",
            "[INFO] Connected to Unity environment with package version 2.3.0-exp.3 and communication version 1.5.0\n",
            "[INFO] Connected new brain: SoccerTwos?team=1\n",
            "[INFO] Connected new brain: SoccerTwos?team=0\n",
            "[INFO] Hyperparameters for behavior name SoccerTwos: \n",
            "\ttrainer_type:\tpoca\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t2048\n",
            "\t  buffer_size:\t20480\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t3\n",
            "\t  vis_encode_type:\tresnet\n",
            "\t  memory:\t\n",
            "\t    sequence_length:\t128\n",
            "\t    memory_size:\t1024\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\teven_checkpoints:\tFalse\n",
            "\tmax_steps:\t50000000\n",
            "\ttime_horizon:\t1000\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\t\n",
            "\t  save_steps:\t20000\n",
            "\t  team_change:\t100000\n",
            "\t  swap_steps:\t10000\n",
            "\t  window:\t10\n",
            "\t  play_against_latest_model_ratio:\t0.5\n",
            "\t  initial_elo:\t1200.0\n",
            "\tbehavioral_cloning:\tNone\n",
            "[INFO] SoccerTwos. Step: 10000. Time Elapsed: 298.516 s. Mean Reward: 0.000. Mean Group Reward: 0.092. Training. ELO: 1201.724.\n",
            "[INFO] SoccerTwos. Step: 20000. Time Elapsed: 556.682 s. Mean Reward: 0.000. Mean Group Reward: 0.154. Training. ELO: 1203.944.\n",
            "[INFO] SoccerTwos. Step: 30000. Time Elapsed: 781.793 s. Mean Reward: 0.000. Mean Group Reward: 0.015. Training.\n",
            "[INFO] SoccerTwos. Step: 40000. Time Elapsed: 1047.003 s. Mean Reward: 0.000. Mean Group Reward: -0.049. Training. ELO: 1204.550.\n",
            "[INFO] SoccerTwos. Step: 50000. Time Elapsed: 1398.968 s. Mean Reward: 0.000. Mean Group Reward: 0.062. Training. ELO: 1205.540.\n",
            "[INFO] SoccerTwos. Step: 60000. Time Elapsed: 1572.123 s. Mean Reward: 0.000. Mean Group Reward: 0.242. Training. ELO: 1208.017.\n",
            "[INFO] SoccerTwos. Step: 70000. Time Elapsed: 1930.857 s. Mean Reward: 0.000. Mean Group Reward: -0.159. Training. ELO: 1210.243.\n",
            "[INFO] SoccerTwos. Step: 80000. Time Elapsed: 2237.718 s. Mean Reward: 0.000. Mean Group Reward: -0.120. Training. ELO: 1210.155.\n",
            "[INFO] SoccerTwos. Step: 90000. Time Elapsed: 2456.688 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1210.656.\n",
            "[INFO] SoccerTwos. Step: 100000. Time Elapsed: 2635.676 s. Mean Reward: 0.000. Mean Group Reward: -0.419. Training. ELO: 1210.656.\n",
            "[INFO] SoccerTwos. Step: 110000. Time Elapsed: 3077.929 s. Mean Reward: 0.000. Mean Group Reward: 0.023. Training. ELO: 1210.656.\n",
            "[INFO] SoccerTwos. Step: 120000. Time Elapsed: 3290.206 s. Mean Reward: 0.000. Mean Group Reward: -0.154. Training. ELO: 1210.656.\n",
            "[INFO] SoccerTwos. Step: 130000. Time Elapsed: 3649.515 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training. ELO: 1210.656.\n",
            "[INFO] SoccerTwos. Step: 140000. Time Elapsed: 3766.916 s. Mean Reward: 0.000. Mean Group Reward: -0.295. Training. ELO: 1210.406.\n",
            "[INFO] SoccerTwos. Step: 150000. Time Elapsed: 4189.803 s. Mean Reward: 0.000. Mean Group Reward: -0.615. Training. ELO: 1207.220.\n",
            "[INFO] SoccerTwos. Step: 160000. Time Elapsed: 4252.619 s. Mean Reward: 0.000. Mean Group Reward: -0.062. Training. ELO: 1206.719.\n",
            "[INFO] SoccerTwos. Step: 170000. Time Elapsed: 4701.976 s. Mean Reward: 0.000. Mean Group Reward: -0.085. Training. ELO: 1205.618.\n",
            "[INFO] SoccerTwos. Step: 180000. Time Elapsed: 4900.612 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1204.880.\n",
            "[INFO] SoccerTwos. Step: 190000. Time Elapsed: 5170.984 s. Mean Reward: 0.000. Mean Group Reward: 0.300. Training. ELO: 1204.634.\n",
            "[INFO] SoccerTwos. Step: 200000. Time Elapsed: 5441.065 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 210000. Time Elapsed: 5897.250 s. Mean Reward: 0.000. Mean Group Reward: -0.069. Training. ELO: 1205.318.\n",
            "[INFO] SoccerTwos. Step: 220000. Time Elapsed: 6060.499 s. Mean Reward: 0.000. Mean Group Reward: 0.144. Training. ELO: 1203.698.\n",
            "[INFO] SoccerTwos. Step: 230000. Time Elapsed: 6417.344 s. Mean Reward: 0.000. Mean Group Reward: 0.096. Training. ELO: 1203.698.\n",
            "[INFO] SoccerTwos. Step: 240000. Time Elapsed: 6640.621 s. Mean Reward: 0.000. Mean Group Reward: 0.004. Training. ELO: 1204.632.\n",
            "[INFO] SoccerTwos. Step: 250000. Time Elapsed: 6966.077 s. Mean Reward: 0.000. Mean Group Reward: 0.113. Training. ELO: 1204.717.\n",
            "[INFO] SoccerTwos. Step: 260000. Time Elapsed: 7137.455 s. Mean Reward: 0.000. Mean Group Reward: -0.068. Training. ELO: 1204.717.\n",
            "[INFO] SoccerTwos. Step: 270000. Time Elapsed: 7491.214 s. Mean Reward: 0.000. Mean Group Reward: -0.286. Training. ELO: 1204.967.\n",
            "[INFO] SoccerTwos. Step: 280000. Time Elapsed: 7689.216 s. Mean Reward: 0.000. Mean Group Reward: 0.082. Training. ELO: 1206.285.\n",
            "[INFO] SoccerTwos. Step: 290000. Time Elapsed: 8038.245 s. Mean Reward: 0.000. Mean Group Reward: -0.121. Training. ELO: 1206.691.\n",
            "[INFO] SoccerTwos. Step: 300000. Time Elapsed: 8213.111 s. Mean Reward: 0.000. Mean Group Reward: -0.204. Training. ELO: 1206.691.\n",
            "[INFO] SoccerTwos. Step: 310000. Time Elapsed: 8654.322 s. Mean Reward: 0.000. Mean Group Reward: -0.139. Training. ELO: 1206.691.\n",
            "[INFO] SoccerTwos. Step: 320000. Time Elapsed: 8828.923 s. Mean Reward: 0.000. Mean Group Reward: -0.183. Training. ELO: 1206.691.\n",
            "[INFO] SoccerTwos. Step: 330000. Time Elapsed: 9161.608 s. Mean Reward: 0.000. Mean Group Reward: 0.221. Training. ELO: 1206.691.\n",
            "[INFO] SoccerTwos. Step: 340000. Time Elapsed: 9431.453 s. Mean Reward: 0.000. Mean Group Reward: 0.180. Training. ELO: 1206.691.\n",
            "[INFO] SoccerTwos. Step: 350000. Time Elapsed: 9725.712 s. Mean Reward: 0.000. Mean Group Reward: -0.151. Training. ELO: 1206.691.\n",
            "[INFO] SoccerTwos. Step: 360000. Time Elapsed: 9904.427 s. Mean Reward: 0.000. Mean Group Reward: 0.127. Training. ELO: 1206.691.\n",
            "[INFO] SoccerTwos. Step: 370000. Time Elapsed: 10265.490 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1206.691.\n",
            "[INFO] SoccerTwos. Step: 380000. Time Elapsed: 10446.043 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1205.937.\n",
            "[INFO] SoccerTwos. Step: 390000. Time Elapsed: 10789.296 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1205.687.\n",
            "[INFO] SoccerTwos. Step: 400000. Time Elapsed: 10984.039 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 410000. Time Elapsed: 11407.020 s. Mean Reward: 0.000. Mean Group Reward: -0.417. Training. ELO: 1202.443.\n",
            "[INFO] SoccerTwos. Step: 420000. Time Elapsed: 11668.122 s. Mean Reward: 0.000. Mean Group Reward: -0.313. Training. ELO: 1199.855.\n",
            "[INFO] SoccerTwos. Step: 430000. Time Elapsed: 12013.029 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1198.065.\n",
            "[INFO] SoccerTwos. Step: 440000. Time Elapsed: 12164.255 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training. ELO: 1197.819.\n",
            "[INFO] SoccerTwos. Step: 450000. Time Elapsed: 12519.003 s. Mean Reward: 0.000. Mean Group Reward: -0.310. Training. ELO: 1197.819.\n",
            "[INFO] SoccerTwos. Step: 460000. Time Elapsed: 12697.331 s. Mean Reward: 0.000. Mean Group Reward: -0.054. Training. ELO: 1197.457.\n",
            "[INFO] SoccerTwos. Step: 470000. Time Elapsed: 13066.377 s. Mean Reward: 0.000. Mean Group Reward: 0.085. Training. ELO: 1197.603.\n",
            "[INFO] SoccerTwos. Step: 480000. Time Elapsed: 13241.439 s. Mean Reward: 0.000. Mean Group Reward: 0.090. Training. ELO: 1198.619.\n",
            "[INFO] SoccerTwos. Step: 490000. Time Elapsed: 13613.525 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 500000. Time Elapsed: 13719.310 s. Mean Reward: 0.000. Mean Group Reward: -0.308. Training. ELO: 1197.127.\n",
            "/usr/local/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:1941: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
            "  warnings.warn(\"Exporting a model to ONNX with a batch_size other than 1, \" +\n",
            "[INFO] Exported results/resnet/SoccerTwos/SoccerTwos-499840.onnx\n",
            "[INFO] SoccerTwos. Step: 510000. Time Elapsed: 14358.582 s. Mean Reward: 0.000. Mean Group Reward: -0.103. Training. ELO: 1195.883.\n",
            "[INFO] SoccerTwos. Step: 520000. Time Elapsed: 14464.194 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1195.142.\n",
            "[INFO] SoccerTwos. Step: 530000. Time Elapsed: 14873.841 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1194.159.\n",
            "[INFO] SoccerTwos. Step: 540000. Time Elapsed: 14986.803 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training. ELO: 1193.914.\n",
            "[INFO] SoccerTwos. Step: 550000. Time Elapsed: 15372.801 s. Mean Reward: 0.000. Mean Group Reward: 0.182. Training. ELO: 1193.914.\n",
            "[INFO] SoccerTwos. Step: 560000. Time Elapsed: 15546.290 s. Mean Reward: 0.000. Mean Group Reward: -0.031. Training. ELO: 1193.424.\n",
            "[INFO] SoccerTwos. Step: 570000. Time Elapsed: 15894.170 s. Mean Reward: 0.000. Mean Group Reward: 0.016. Training. ELO: 1193.931.\n",
            "[INFO] SoccerTwos. Step: 580000. Time Elapsed: 16090.204 s. Mean Reward: 0.000. Mean Group Reward: -0.250. Training. ELO: 1193.504.\n",
            "[INFO] SoccerTwos. Step: 590000. Time Elapsed: 16466.393 s. Mean Reward: 0.000. Mean Group Reward: 0.180. Training. ELO: 1193.923.\n",
            "[INFO] SoccerTwos. Step: 600000. Time Elapsed: 16674.008 s. Mean Reward: 0.000. Mean Group Reward: 0.072. Training.\n",
            "[INFO] SoccerTwos. Step: 610000. Time Elapsed: 17108.261 s. Mean Reward: 0.000. Mean Group Reward: -0.245. Training. ELO: 1193.635.\n",
            "[INFO] SoccerTwos. Step: 620000. Time Elapsed: 17253.809 s. Mean Reward: 0.000. Mean Group Reward: 0.032. Training. ELO: 1194.347.\n",
            "[INFO] SoccerTwos. Step: 630000. Time Elapsed: 17594.679 s. Mean Reward: 0.000. Mean Group Reward: 0.259. Training. ELO: 1196.220.\n",
            "[INFO] SoccerTwos. Step: 640000. Time Elapsed: 17856.806 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 650000. Time Elapsed: 18188.076 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1196.965.\n",
            "[INFO] SoccerTwos. Step: 660000. Time Elapsed: 18324.829 s. Mean Reward: 0.000. Mean Group Reward: -0.108. Training. ELO: 1196.965.\n",
            "[INFO] SoccerTwos. Step: 670000. Time Elapsed: 18720.526 s. Mean Reward: 0.000. Mean Group Reward: 0.075. Training. ELO: 1197.707.\n",
            "[INFO] SoccerTwos. Step: 680000. Time Elapsed: 18882.194 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1197.199.\n",
            "[INFO] SoccerTwos. Step: 690000. Time Elapsed: 19213.562 s. Mean Reward: 0.000. Mean Group Reward: -0.203. Training. ELO: 1197.893.\n",
            "[INFO] SoccerTwos. Step: 700000. Time Elapsed: 19496.730 s. Mean Reward: 0.000. Mean Group Reward: 0.146. Training. ELO: 1197.690.\n",
            "[INFO] SoccerTwos. Step: 710000. Time Elapsed: 19948.673 s. Mean Reward: 0.000. Mean Group Reward: -0.093. Training. ELO: 1197.119.\n",
            "[INFO] SoccerTwos. Step: 720000. Time Elapsed: 20032.744 s. Mean Reward: 0.000. Mean Group Reward: -0.333. Training. ELO: 1196.916.\n",
            "[INFO] SoccerTwos. Step: 730000. Time Elapsed: 20428.949 s. Mean Reward: 0.000. Mean Group Reward: 0.142. Training. ELO: 1196.789.\n",
            "[INFO] SoccerTwos. Step: 740000. Time Elapsed: 20582.220 s. Mean Reward: 0.000. Mean Group Reward: -0.242. Training. ELO: 1196.882.\n",
            "[INFO] SoccerTwos. Step: 750000. Time Elapsed: 20970.523 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 760000. Time Elapsed: 21181.224 s. Mean Reward: 0.000. Mean Group Reward: -0.258. Training. ELO: 1194.927.\n",
            "[INFO] SoccerTwos. Step: 770000. Time Elapsed: 21507.667 s. Mean Reward: 0.000. Mean Group Reward: 0.003. Training. ELO: 1195.615.\n",
            "[INFO] SoccerTwos. Step: 780000. Time Elapsed: 21725.475 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1194.611.\n",
            "[INFO] SoccerTwos. Step: 790000. Time Elapsed: 22089.234 s. Mean Reward: 0.000. Mean Group Reward: -0.010. Training. ELO: 1195.112.\n",
            "[INFO] SoccerTwos. Step: 800000. Time Elapsed: 22213.867 s. Mean Reward: 0.000. Mean Group Reward: -0.162. Training. ELO: 1195.610.\n",
            "[INFO] SoccerTwos. Step: 810000. Time Elapsed: 22663.785 s. Mean Reward: 0.000. Mean Group Reward: -0.003. Training. ELO: 1197.480.\n",
            "[INFO] SoccerTwos. Step: 820000. Time Elapsed: 22962.500 s. Mean Reward: 0.000. Mean Group Reward: -0.013. Training. ELO: 1197.852.\n",
            "[INFO] SoccerTwos. Step: 830000. Time Elapsed: 23303.180 s. Mean Reward: 0.000. Mean Group Reward: 0.047. Training. ELO: 1197.852.\n",
            "[INFO] SoccerTwos. Step: 840000. Time Elapsed: 23461.203 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1197.852.\n"
          ]
        }
      ]
    }
  ]
}